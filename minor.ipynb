{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-21T15:58:12.942919Z","iopub.execute_input":"2022-03-21T15:58:12.943173Z","iopub.status.idle":"2022-03-21T15:58:12.953947Z","shell.execute_reply.started":"2022-03-21T15:58:12.943144Z","shell.execute_reply":"2022-03-21T15:58:12.952881Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-03-21T15:58:22.968287Z","iopub.execute_input":"2022-03-21T15:58:22.968575Z","iopub.status.idle":"2022-03-21T15:58:22.992176Z","shell.execute_reply.started":"2022-03-21T15:58:22.968544Z","shell.execute_reply":"2022-03-21T15:58:22.991064Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import regularizers\nimport tensorflow.keras.utils as ku \nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-03-21T15:58:44.033198Z","iopub.execute_input":"2022-03-21T15:58:44.033474Z","iopub.status.idle":"2022-03-21T15:58:44.041877Z","shell.execute_reply.started":"2022-03-21T15:58:44.033443Z","shell.execute_reply":"2022-03-21T15:58:44.041054Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer()\ndata = open('../input/Helloworld/poem.txt').read()\n\ncorpus = data.lower().split(\"\\n\")\n\n\ntokenizer.fit_on_texts(corpus)\ntotal_words = len(tokenizer.word_index) + 1\n\n# create input sequences using list of tokens\ninput_sequences = []\nfor line in corpus:\n    token_list = tokenizer.texts_to_sequences([line])[0]\n    for i in range(1, len(token_list)):\n        n_gram_sequence = token_list[:i+1]\n        input_sequences.append(n_gram_sequence)\n\n\n# pad sequences \nmax_sequence_len = max([len(x) for x in input_sequences])\ninput_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n\n# create predictors and label\npredictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n\nlabel = ku.to_categorical(label, num_classes=total_words)\n\nprint(max_sequence_len)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T15:58:47.602505Z","iopub.execute_input":"2022-03-21T15:58:47.603093Z","iopub.status.idle":"2022-03-21T15:58:47.791071Z","shell.execute_reply.started":"2022-03-21T15:58:47.603058Z","shell.execute_reply":"2022-03-21T15:58:47.790311Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\nmodel.add(Bidirectional(LSTM(150, return_sequences = True)))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(100))\nmodel.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\nmodel.add(Dense(total_words, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-21T15:58:50.513783Z","iopub.execute_input":"2022-03-21T15:58:50.514622Z","iopub.status.idle":"2022-03-21T15:58:53.521976Z","shell.execute_reply.started":"2022-03-21T15:58:50.514567Z","shell.execute_reply":"2022-03-21T15:58:53.521278Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(model.summary())","metadata":{"execution":{"iopub.status.busy":"2022-03-21T15:58:53.523338Z","iopub.execute_input":"2022-03-21T15:58:53.523568Z","iopub.status.idle":"2022-03-21T15:58:53.533738Z","shell.execute_reply.started":"2022-03-21T15:58:53.523536Z","shell.execute_reply":"2022-03-21T15:58:53.533034Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"history = model.fit(predictors, label, epochs=300, verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-21T15:59:00.420035Z","iopub.execute_input":"2022-03-21T15:59:00.420336Z","iopub.status.idle":"2022-03-21T16:23:36.292953Z","shell.execute_reply.started":"2022-03-21T15:59:00.420305Z","shell.execute_reply":"2022-03-21T16:23:36.292117Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(\"Model Accuracy: \"+str(history.history['accuracy'][len(history.history['accuracy'])-1]))\nprint(\"Model Loss: \"+str(history.history['loss'][len(history.history['loss'])-1]))","metadata":{"execution":{"iopub.status.busy":"2022-03-21T16:23:36.305299Z","iopub.execute_input":"2022-03-21T16:23:36.305767Z","iopub.status.idle":"2022-03-21T16:23:36.315974Z","shell.execute_reply.started":"2022-03-21T16:23:36.305725Z","shell.execute_reply":"2022-03-21T16:23:36.314960Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nloss = history.history['loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.title('Training accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.title('Training loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T16:23:36.318427Z","iopub.execute_input":"2022-03-21T16:23:36.318870Z","iopub.status.idle":"2022-03-21T16:23:36.710755Z","shell.execute_reply.started":"2022-03-21T16:23:36.318830Z","shell.execute_reply":"2022-03-21T16:23:36.710046Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"seed_text = \"envy moon\"\nnext_words = 10\n  \nfor _ in range(next_words):\n    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n    prediction=model.predict(token_list) \n    predicted=np.argmax(prediction,axis=1)\n    output_word = \"\"\n    for word, index in tokenizer.word_index.items():\n        if index == predicted:\n            output_word = word\n            break\n    seed_text += \" \" + output_word\nprint(seed_text)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T16:34:12.425671Z","iopub.execute_input":"2022-03-21T16:34:12.426405Z","iopub.status.idle":"2022-03-21T16:34:12.796201Z","shell.execute_reply.started":"2022-03-21T16:34:12.426366Z","shell.execute_reply":"2022-03-21T16:34:12.795477Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"seed_text = \"black and white dog\"\nnext_words = 20\n  \nfor _ in range(next_words):\n    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n    prediction=model.predict(token_list) \n    predicted=np.argmax(prediction,axis=1)\n    output_word = \"\"\n    for word, index in tokenizer.word_index.items():\n        if index == predicted:\n            output_word = word\n            break\n    seed_text += \" \" + output_word\nprint(seed_text)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T16:33:18.008557Z","iopub.execute_input":"2022-03-21T16:33:18.008830Z","iopub.status.idle":"2022-03-21T16:33:18.698595Z","shell.execute_reply.started":"2022-03-21T16:33:18.008800Z","shell.execute_reply":"2022-03-21T16:33:18.696947Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}